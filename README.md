# Digit Classification Neural Network (MNIST) in C

This project implements a multi-layer neural network in pure C for handwritten digit classification using the MNIST dataset. The implementation uses optimized matrix operations and C programming techniques for efficient data processing.

## üîç Project Description

This program implements a fully connected, feed-forward neural network with 4 layers:
- Processes 28x28 pixel images (784 features) of handwritten digits
- Uses the ReLU activation function in hidden layers
- Classifies digits from 0 to 9
- Evaluates model performance with accuracy metrics
- Allows ASCII visualization of images and predictions

## üèóÔ∏è Neural Network Architecture

The neural network has the following architecture:

```
Input: 784 neurons (28x28 image)
    ‚Üì
Layer 1: 784 ‚Üí 200 neurons + ReLU
    ‚Üì
Layer 2: 200 ‚Üí 100 neurons + ReLU
    ‚Üì
Layer 3: 100 ‚Üí 50 neurons + ReLU
    ‚Üì
Layer 4: 50 ‚Üí 10 neurons (output)
    ‚Üì
Argmax: Final classification (0-9)
```

## üìÅ Project Structure

```
DigiNet/
‚îú‚îÄ‚îÄ digiNet.c           # Main source code
‚îú‚îÄ‚îÄ digiNet.h           # Application header
‚îú‚îÄ‚îÄ func.c              # Neural network and utility functions
‚îú‚îÄ‚îÄ README.md           
‚îú‚îÄ‚îÄ csvs/
‚îÇ   ‚îú‚îÄ‚îÄ data.csv        # MNIST dataset
‚îÇ   ‚îî‚îÄ‚îÄ digits.csv      # Digit labels (60,000 samples)
‚îî‚îÄ‚îÄ parameters/
    ‚îú‚îÄ‚îÄ weights0_1.csv  # Layer 1 weights (784x200)
    ‚îú‚îÄ‚îÄ weights1_1.csv  # Layer 2 weights (200x100)
    ‚îú‚îÄ‚îÄ weights2_1.csv  # Layer 3 weights (100x50)
    ‚îú‚îÄ‚îÄ weights3_1.csv  # Layer 4 weights (50x10)
    ‚îú‚îÄ‚îÄ biases0_1.csv   # Layer 1 biases (200 values)
    ‚îú‚îÄ‚îÄ biases1_1.csv   # Layer 2 biases (100 values)
    ‚îú‚îÄ‚îÄ biases2_1.csv   # Layer 3 biases (50 values)
    ‚îî‚îÄ‚îÄ biases3_1.csv   # Layer 4 biases (10 values)
```



## üöÄ Compilation and Execution

### Requirements
- GCC compiler
- POSIX-compatible OS (Linux, macOS, WSL, or Windows with GCC)
- At least 500MB of free RAM to load the dataset

### Compilation
```bash
gcc -o digiNet digiNet.c func.c
```

### Execution
```bash
./digiNet 1
```

The numeric argument indicates the number of processes (currently only 1 is supported).


## üìä Features

### Data Loading
- **Dataset**: 60,000 MNIST training images
- **Format**: CSV files with normalized pixel values
- **Labels**: Digits from 0 to 9

### Implemented Operations
1. **Matrix multiplication** (`mat_mul`): Matrix product A √ó B
2. **Vector addition** (`sum_vect`): Adds bias vector to each matrix row
3. **ReLU function** (`relu`): max(0, x) element-wise
4. **Argmax** (`argmax`): Finds the class with the highest probability

### Model Evaluation
- Calculates total model accuracy
- Shows execution time statistics for each operation
- Allows inspection of individual images and predictions

### Visualization
The program includes a function to display images in ASCII format:
- `#` for very dark pixels (>191)
- `$` for dark pixels (127-191)
- `O` for gray pixels (63-127)
- `.` for light pixels (<63)


## üîß Technical Details

### Memory Management
- Dynamic allocation with `malloc` for all matrices
- Proper memory release with `free`
- Error handling in all file operations

### Performance Measurement
The program measures the execution time of each operation using `clock()`:
- Data loading
- Matrix multiplications
- Activation function application
- Prediction calculation

### Error Handling
- File opening verification
- Data type conversion control
- Input range validation

## üìà Expected Performance

With the included pretrained parameters, the model should achieve approximately 85-95% accuracy on the test dataset.


## üõ†Ô∏è Possible Improvements

- [ ] Separate folders for functions and main code
- [ ] Add functions to improve data visualization
- [ ] Implement real parallelization for multiple processes

## üìù Notes

- The project is designed for educational and demonstration purposes
- The weights are pretrained and do not require a training phase
- The implementation prioritizes code clarity over computational efficiency

## ü§ù Contributions

This project is part of an academic assignment. Contributions are welcome to improve the implementation or add new features.

---

**Course**: Introduction to Computer Networks and Operating Systems
**University**: University of the Basque Country (UPV/EHU)

---

# Red Neuronal para Clasificaci√≥n de D√≠gitos (MNIST) en C

Este proyecto implementa una red neuronal multicapa en C puro para la clasificaci√≥n de d√≠gitos manuscritos del dataset MNIST. La implementaci√≥n utiliza operaciones matriciales optimizadas y t√©cnicas de programaci√≥n en C para el procesamiento eficiente de datos.

## üîç Descripci√≥n del Proyecto

Este programa implementa una red neuronal feed-forward de 4 capas completamente conectadas que:
- Procesa im√°genes de 28x28 p√≠xeles (784 caracter√≠sticas) de d√≠gitos manuscritos
- Utiliza la funci√≥n de activaci√≥n ReLU en capas ocultas
- Clasifica d√≠gitos del 0 al 9
- Eval√∫a el rendimiento del modelo con m√©tricas de precisi√≥n
- Permite visualizaci√≥n ASCII de las im√°genes y predicciones

## üèóÔ∏è Arquitectura de la Red Neuronal

La red neuronal tiene la siguiente arquitectura:

```
Entrada: 784 neuronas (imagen 28x28)
    ‚Üì
Capa 1: 784 ‚Üí 200 neuronas + ReLU
    ‚Üì
Capa 2: 200 ‚Üí 100 neuronas + ReLU
    ‚Üì
Capa 3: 100 ‚Üí 50 neuronas + ReLU
    ‚Üì
Capa 4: 50 ‚Üí 10 neuronas (salida)
    ‚Üì
Argmax: Clasificaci√≥n final (0-9)
```


## üìÅ Estructura del Proyecto

```
DigiNet/
‚îú‚îÄ‚îÄ digiNet.c           # C√≥digo fuente principal
‚îú‚îÄ‚îÄ digiNet.h           # Librer√≠a de la aplicaci√≥n
‚îú‚îÄ‚îÄ func.c              # Funciones de red neuronal y utilidades
‚îú‚îÄ‚îÄ README.md           
‚îú‚îÄ‚îÄ csvs/
‚îÇ   ‚îú‚îÄ‚îÄ data.csv        # Dataset MNIST
‚îÇ   ‚îî‚îÄ‚îÄ digits.csv      # Etiquetas de los d√≠gitos (60,000 muestras)
‚îî‚îÄ‚îÄ parameters/
    ‚îú‚îÄ‚îÄ weights0_1.csv  # Pesos de la capa 1 (784x200)
    ‚îú‚îÄ‚îÄ weights1_1.csv  # Pesos de la capa 2 (200x100)
    ‚îú‚îÄ‚îÄ weights2_1.csv  # Pesos de la capa 3 (100x50)
    ‚îú‚îÄ‚îÄ weights3_1.csv  # Pesos de la capa 4 (50x10)
    ‚îú‚îÄ‚îÄ biases0_1.csv   # Sesgos de la capa 1 (200 valores)
    ‚îú‚îÄ‚îÄ biases1_1.csv   # Sesgos de la capa 2 (100 valores)
    ‚îú‚îÄ‚îÄ biases2_1.csv   # Sesgos de la capa 3 (50 valores)
    ‚îî‚îÄ‚îÄ biases3_1.csv   # Sesgos de la capa 4 (10 valores)
```

## üöÄ Compilaci√≥n y Ejecuci√≥n

### Requisitos
- Compilador GCC
- Sistema operativo compatible con POSIX (Linux, macOS, WSL)
- Al menos 500MB de RAM libre para cargar el dataset

### Compilaci√≥n
```bash
gcc -o digiNet digiNet.c func.c
```

### Ejecuci√≥n
```bash
./digiNet 1
```

El argumento num√©rico indica el n√∫mero de procesos (actualmente solo soporta 1).

## üìä Funcionalidades

### Carga de Datos
- **Dataset**: 60,000 im√°genes de entrenamiento del MNIST
- **Formato**: Archivos CSV con valores de p√≠xeles normalizados
- **Etiquetas**: D√≠gitos del 0 al 9

### Operaciones Implementadas
1. **Multiplicaci√≥n de matrices** (`mat_mul`): Producto matricial A √ó B
2. **Suma vectorial** (`sum_vect`): Suma de vector bias a cada fila de la matriz
3. **Funci√≥n ReLU** (`relu`): max(0, x) elemento a elemento
4. **Argmax** (`argmax`): Encuentra la clase con mayor probabilidad

### Evaluaci√≥n del Modelo
- Calcula la precisi√≥n total del modelo
- Muestra estad√≠sticas de tiempo de ejecuci√≥n por operaci√≥n
- Permite inspecci√≥n individual de im√°genes y predicciones

### Visualizaci√≥n
El programa incluye una funci√≥n para mostrar las im√°genes en formato ASCII:
- `#` para p√≠xeles muy oscuros (>191)
- `$` para p√≠xeles oscuros (127-191)
- `O` para p√≠xeles grises (63-127)
- `.` para p√≠xeles claros (<63)

## üîß Detalles T√©cnicos

### Gesti√≥n de Memoria
- Allocaci√≥n din√°mica con `malloc` para todas las matrices
- Liberaci√≥n apropiada de memoria con `free`
- Control de errores en todas las operaciones de archivo

### Medici√≥n de Rendimiento
El programa mide el tiempo de ejecuci√≥n de cada operaci√≥n usando `clock()`:
- Carga de datos
- Multiplicaciones matriciales
- Aplicaci√≥n de funciones de activaci√≥n
- C√°lculo de predicciones

### Manejo de Errores
- Verificaci√≥n de apertura de archivos
- Control de conversi√≥n de tipos de datos
- Validaci√≥n de rangos de entrada

## üìà Rendimiento Esperado

Con los par√°metros preentrenados incluidos, el modelo deber√≠a alcanzar una precisi√≥n aproximada del 85-95% en el dataset de prueba.

## üõ†Ô∏è Posibles Mejoras

- [ ] Separaci√≥n de carpetas en funciones y codigo principal
- [ ] A√±adir funciones para mejorar la visibilidad de los datos
- [ ] Implementaci√≥n de paralelizaci√≥n real para m√∫ltiples procesos

## üìù Notas

- El proyecto est√° dise√±ado para fines educativos y de demostraci√≥n
- Los pesos est√°n preentrenados y no requieren fase de entrenamiento
- La implementaci√≥n prioriza la claridad del c√≥digo sobre la eficiencia computacional

## ü§ù Contribuciones

Este proyecto es parte de un trabajo acad√©mico. Las contribuciones son bienvenidas para mejorar la implementaci√≥n o a√±adir nuevas funcionalidades.

---

**Curso**: Introducci√≥n a las Redes de Computadores y Sistemas Operativos
**Universidad**: Universidad del Pa√≠s Vasco (UPV/EHU)